
## Архитектуры информационных систем

Архитектура информационной системы определяет, как компоненты системы взаимодействуют друг с другом, как распределяются данные и вычисления. Выбор архитектуры зависит от требований к масштабируемости, надежности, производительности и сложности системы. Рассмотрим три основные архитектуры: **файл-сервер**, **клиент-сервер** и **peer-to-peer (P2P)**.

### 1. Файл-серверная архитектура

В этой архитектуре центральный сервер хранит все данные (например, файлы), а клиенты обращаются к нему для чтения или записи. Логика обработки данных выполняется на стороне клиента.

- **Как работает**: Клиент запрашивает файл у сервера, сервер отправляет файл, а клиент обрабатывает его локально (например, открывает документ в текстовом редакторе).
- **Примеры**:
    - Сетевые файловые хранилища (NAS), такие как Samba или NFS.
    - Ранние системы управления базами данных, где клиентская программа запрашивала сырые данные.
- **Преимущества**:
    - Простота реализации и управления.
    - Централизованное хранение данных упрощает резервное копирование и контроль доступа.
- **Недостатки**:
    - Высокая нагрузка на сервер при большом количестве запросов, так как он передает большие объемы данных.
    - Ограниченная масштабируемость, так как сервер становится узким местом.
    - Зависимость от пропускной способности сети.
- **Аналогия**: Представьте библиотеку, где все книги хранятся в одном месте, а читатели (клиенты) берут книги, чтобы работать с ними дома. Если библиотекарь один, а читателей много, образуется очередь.

**Когда использовать**: Для небольших систем с ограниченным числом пользователей, где важна простота (например, корпоративные файловые хранилища).

### 2. Клиент-серверная архитектура

В клиент-серверной архитектуре сервер выполняет основную логику обработки данных, а клиент отправляет запросы и получает результаты. Это наиболее распространенная архитектура для веб-приложений и современных систем.

- **Как работает**: Клиент (например, браузер) отправляет запрос к серверу (например, API-запрос). Сервер обрабатывает запрос (выполняет вычисления, взаимодействует с базой данных) и возвращает ответ (например, JSON или HTML).
- **Примеры**:
    - Веб-приложения (браузер запрашивает страницы у сервера).
    - Мобильные приложения, взаимодействующие с бэкендом через REST/GraphQL API.
    - Банковские системы, где клиентский терминал отправляет транзакции на сервер.
- **Преимущества**:
    - Централизованная логика упрощает обновления и управление.
    - Сервер может быть оптимизирован для обработки сложных вычислений.
    - Поддерживает масштабируемость (например, через балансировщики нагрузки).
- **Недостатки**:
    - Сервер — потенциальное узкое место, требует высокой надежности.
    - Задержки сети могут влиять на производительность.
    - Требуется обеспечение безопасности передачи данных.
- **Аналогия**: Представьте ресторан, где клиенты (пользователи) делают заказы официанту (клиенту), а кухня (сервер) готовит еду и отправляет ее обратно. Кухня отвечает за качество и сложность блюд, а клиенты просто наслаждаются результатом.

**Когда использовать**: Для большинства современных приложений, от веб-сайтов до банковских систем, где важна централизованная обработка данных и масштабируемость.

### 3. Peer-to-Peer (P2P) архитектура

В P2P-архитектуре нет центрального сервера — все узлы (пиры) равноправны и могут одновременно быть клиентами и серверами. Каждый пир хранит и передает данные другим пирам.

- **Как работает**: Узлы обмениваются данными напрямую. Например, в BitTorrent каждый участник скачивает и одновременно раздает части файла.
- **Примеры**:
    - Файлообменные сети (BitTorrent, eMule).
    - Блокчейн-сети (Bitcoin, Ethereum), где узлы хранят копии распределенного реестра.
    - Мессенджеры с прямой передачей данных (например, Tox).
- **Преимущества**:
    - Высокая устойчивость к сбоям: выход одного узла не ломает систему.
    - Масштабируемость: чем больше узлов, тем больше ресурсов.
    - Нет единой точки отказа.
- **Недостатки**:
    - Сложность управления и обеспечения безопасности.
    - Производительность зависит от активности и ресурсов узлов.
    - Сложно гарантировать целостность данных без дополнительных механизмов (например, консенсуса в блокчейне).
- **Аналогия**: Представьте фермерский рынок, где каждый участник одновременно продает и покупает продукты напрямую у других. Нет центрального склада, и все зависит от активности участников.

**Когда использовать**: Для децентрализованных систем, где важна устойчивость и распределенность (например, блокчейн, файлообменники).

---

## Основные критерии информационных систем

При проектировании информационных систем важно учитывать ключевые критерии, которые определяют их эффективность и пригодность для конкретных задач. Эти критерии включают надежность, масштабируемость, состояние (stateless/stateful), производительность, удобство сопровождения и безопасность.

### 1. Надежность (Reliability)

Надежность — это способность системы работать без сбоев и обеспечивать ожидаемые результаты даже при частичных отказах компонентов.

- **Ключевые метрики**:
    - **SLO (Service Level Objective)**: Целевые показатели надежности, которые система должна достигать (например, 99.9% времени доступности).
    - **SLA (Service Level Agreement)**: Договор с пользователями, где прописаны гарантии надежности и штрафы за их нарушение (например, компенсация за простой).
    - **SLI (Service Level Indicator)**: Измеримые показатели, которые отслеживают выполнение SLO (например, процент успешных запросов).
- **Как обеспечивается**:
    - Резервирование (redundancy): дублирование критических компонентов.
    - Обработка ошибок: graceful degradation (система продолжает работать в ограниченном режиме при сбоях).
    - Мониторинг и алертинг: инструменты вроде Prometheus для отслеживания состояния системы.
- **Пример**: В банковской системе надежность критически важна. Если сервер упадет во время перевода денег, транзакция должна либо завершиться корректно, либо быть откатана. Используются распределенные транзакции и отказоустойчивые базы данных (например, PostgreSQL с репликацией).
- **Аналогия**: Надежность — как мост, который должен выдерживать нагрузку даже при сильном ветре или поломке одной опоры.

### 2. Масштабируемость (Scalability)

Масштабируемость — это способность системы справляться с увеличением нагрузки (например, числа пользователей или запросов) без значительных изменений в архитектуре.

- **Типы масштабирования**:
    - **Вертикальное (Vertical Scaling)**: Увеличение мощности одного сервера (больше CPU, RAM). Простое, но ограниченное решение, так как сервер имеет физические пределы.
        - Пример: Увеличение памяти сервера для базы данных MySQL.
    - **Горизонтальное (Horizontal Scaling)**: Добавление новых серверов в систему. Требует распределенной архитектуры, но позволяет масштабироваться практически бесконечно.
        - Пример: Добавление новых нод в кластер Kubernetes для обработки веб-запросов.
- **Как обеспечивается**:
    - Использование балансировщиков нагрузки (например, NGINX, AWS ELB).
    - Разделение данных (шардинг) и кэширование (Redis, Memcached).
    - Микросервисная архитектура для независимого масштабирования компонентов.
- **Пример**: Соцсеть вроде Twitter масштабируется горизонтально, добавляя серверы для обработки твитов, когда число пользователей растет.
- **Аналогия**: Вертикальное масштабирование — как замена маленького грузовика на более мощный, а горизонтальное — как добавление новых грузовиков в автопарк.

### 3. Состояние (Stateless/Stateful)

Состояние системы определяет, хранит ли она данные между запросами.

- **Stateless (Без состояния)**: Каждый запрос обрабатывается независимо, без сохранения данных о предыдущих запросах на сервере.
    - Преимущества: Простота масштабирования, так как любой сервер может обработать запрос.
    - Пример: REST API для получения списка постов в соцсети.
- **Stateful (С состоянием)**: Сервер хранит данные о состоянии (например, сессии пользователя).
    - Преимущества: Удобно для приложений, где важно сохранять контекст (например, чаты).
    - Недостатки: Сложнее масштабировать, так как запросы должны направляться к одному серверу.
- **Как управлять**:
    - Для stateless: Используйте токены (JWT) или внешние хранилища (Redis для сессий).
    - Для stateful: Репликация состояния или sticky sessions.
- **Пример**: В мессенджере (stateful) сервер должен помнить, какие сообщения уже доставлены пользователю. В поисковой системе (stateless) каждый запрос обрабатывается независимо.
- **Аналогия**: Stateless — как кассир в супермаркете, который не помнит предыдущих покупателей. Stateful — как личный менеджер, который знает всю вашу историю покупок.

### 4. Производительность (Performance)

Производительность измеряет, насколько быстро и эффективно система обрабатывает запросы.

- **Ключевые метрики**:
    - **Latency (Задержка)**: Время, необходимое для обработки одного запроса (например, 100 мс для загрузки страницы).
    - **Response Time**: Полное время, включая задержки сети.
    - **Throughput (Пропускная способность)**: Количество запросов, которые система может обработать за единицу времени (например, 1000 rps).
- **Типы приложений**:
    - **Low-latency apps**: Приложения, где важна минимальная задержка (например, биржевые платформы, где задержка в 1 мс может стоить миллионов).
    - **High-throughput apps**: Приложения, где важна способность обрабатывать большой объем запросов (например, стриминговые сервисы вроде Netflix).
- **Как оптимизировать**:
    - Кэширование (например, CDN для статического контента).
    - Асинхронная обработка (например, очереди с RabbitMQ).
    - Оптимизация базы данных (индексы, денормализация).
- **Пример**: В e-commerce системе низкая задержка важна для быстрой загрузки каталога, а высокая пропускная способность — для обработки тысяч заказов в Черную пятницу.
- **Аналогия**: Latency — как время, за которое повар готовит одно блюдо. Throughput — как количество блюд, которое кухня может приготовить за час.

### 5. Удобство сопровождения (Maintainability)

Удобство сопровождения определяет, насколько легко поддерживать, обновлять и расширять систему.

- **Как обеспечивается**:
    - Чистый код и документация.
    - Модульная архитектура (например, микросервисы).
    - Автоматизированное тестирование (unit tests, integration tests).
    - CI/CD для быстрого развертывания.
- **Пример**: В банковской системе удобство сопровождения важно для быстрого внедрения новых функций (например, поддержка новых типов платежей).
- **Аналогия**: Система — как автомобиль. Если детали легко заменяемы и есть инструкция, ремонт проходит быстро.

### 6. Безопасность (Security)

Безопасность — это защита системы от несанкционированного доступа, утечек данных и атак.

- **Как обеспечивается**:
    - Шифрование данных (TLS для передачи, AES для хранения).
    - Аутентификация и авторизация (OAuth, JWT).
    - Защита от атак (DDoS, SQL-инъекции) с помощью WAF и валидации входных данных.
    - Регулярные аудиты безопасности.
- **Пример**: В медицинской системе утечка данных о пациентах недопустима, поэтому используются многоуровневая аутентификация и шифрование.
- **Аналогия**: Безопасность — как замки на дверях дома. Чем больше слоев защиты (кодовый замок, сигнализация), тем сложнее взломать.

---

## Основные свойства информационных систем

### Что такое высокая нагрузка (High Load)?

Высокая нагрузка — это не только про количество запросов в секунду (rps), но и про то, как система справляется с этими запросами.

- **20 rps vs 20 000 rps**:
    - 20 rps могут быть высоконагруженными, если каждый запрос требует сложных вычислений (например, рендеринг 3D-модели).
    - 20 000 rps могут быть легкими, если запросы простые (например, чтение статического контента из кэша).
- **Ключевой принцип**: Смотрите на характер нагрузки, а не только на цифры. Например:
    - Система машинного обучения с 20 rps, где каждый запрос — это обработка видео, может быть тяжелее, чем веб-сайт с 20 000 rps для выдачи текстовых данных.
- **Пример**: В стриминговом сервисе вроде YouTube высокая нагрузка возникает из-за тысяч одновременных стримов, а в системе анализа логов — из-за записи миллионов событий в секунду.
- **Аналогия**: Два человека могут нести разный груз. Один несет 20 кг кирпичей, а другой — 20 000 листов бумаги. Нагрузка зависит от типа груза, а не только от количества.

### 1. Data-Intensive системы

Data-intensive системы ориентированы на работу с большими объемами данных, их хранение, поиск и фильтрацию.

- **Характеристики**:
    - Хранение больших объемов данных (терабайты, петабайты).
    - Кэширование результатов ресурсоемких операций.
    - Поддержка поиска и фильтрации (например, полнотекстовый поиск).
- **Примеры**:
    - Поисковые системы (Google, Elasticsearch для поиска по логам).
    - Соцсети, где хранятся миллиарды постов и комментариев.
    - Аналитические платформы (Snowflake, BigQuery).
- **Технологии**:
    - Базы данных: PostgreSQL, MongoDB, Cassandra.
    - Кэши: Redis, Memcached.
    - Поисковые движки: Elasticsearch, Solr.
- **Аналогия**: Data-intensive система — как огромный склад, где нужно не только хранить товары, но и быстро находить нужный среди миллионов коробок.

### 2. Compute-Intensive системы

Compute-intensive системы фокусируются на выполнении сложных вычислений, требующих значительных процессорных ресурсов.

- **Характеристики**:
    - Выполнение ресурсоемких вычислений (например, машинное обучение, рендеринг графики).
    - Обработка больших объемов данных в реальном времени.
- **Примеры**:
    - Системы машинного обучения (TensorFlow, PyTorch).
    - Платформы для обработки видео (например, рендеринг фильмов Pixar).
    - Научные симуляции (моделирование климата).
- **Технологии**:
    - GPU/TPU для параллельных вычислений.
    - Фреймворки: CUDA, Apache Spark.
- **Аналогия**: Compute-intensive система — как суперкомпьютер, решающий сложную математическую задачу, где процессор работает на пределе.

### 3. Read/Write Ratio (Соотношение чтения и записи)

Соотношение операций чтения и записи определяет архитектуру системы и выбор технологий.

- **Read-Heavy системы**:
    - Большинство запросов — это чтение данных.
    - Пример: Соцсети (чтение постов), новостные сайты.
    - Оптимизации: Кэширование (CDN, Redis), репликация баз данных.
- **Write-Heavy системы**:
    - Большинство запросов — это запись данных.
    - Пример: Системы логов, IoT-устройства, записывающие телеметрию.
    - Оптимизации: Асинхронная запись, очереди (Kafka), шардинг.
- **Как проектировать**:
    - Для read-heavy: Используйте несколько реплик базы данных и кэши.
    - Для write-heavy: Используйте очереди и распределенные базы данных (Cassandra, DynamoDB).
- **Пример**: В Twitter чтение (просмотр твитов) преобладает над записью (публикация твитов), поэтому используются кэши и CDN. В системе мониторинга серверов запись логов доминирует, поэтому применяются очереди и базы с высокой скоростью записи.
- **Аналогия**: Read-heavy — как библиотека, где люди чаще читают книги. Write-heavy — как журнал, куда постоянно вносят новые записи.

---

## Архитектура бэкенда

Бэкенд-архитектура определяет, как организован серверный код и как компоненты взаимодействуют друг с другом. Основные подходы: **монолитная** и **микросервисная** архитектуры.

### 1. Монолитная архитектура

В монолите весь код (логика, база данных, API) находится в одном приложении.

- **Преимущества**:
    - Простота разработки и тестирования на ранних этапах.
    - Легче отлаживать, так как все в одном месте.
    - Высокая производительность для low-latency приложений, так как нет сетевых вызовов.
- **Недостатки**:
    - Сложно масштабировать отдельные компоненты.
    - Изменение одной части может затронуть всю систему.
    - Трудности с внедрением новых технологий.
- **Пример**: Небольшой стартап, разрабатывающий MVP интернет-магазина, использует монолит (например, Django + PostgreSQL).
- **Когда использовать**: Для стартапов, прототипов или систем, где важна минимальная задержка (например, финансовые приложения).

### 2. Микросервисная архитектура

В микросервисной архитектуре приложение разделено на независимые сервисы, каждый из которых отвечает за свою задачу.

- **Что такое микросервис**:
    - Не обязательно маленький по размеру, но ограничен по зоне ответственности (например, сервис оплаты, сервис уведомлений).
    - Самодостаточен: имеет свою базу данных, API и логику.
    - Общается с другими сервисами через API (REST, gRPC) или очереди (Kafka).
- **Преимущества**:
    - **Независимые релизы**: Каждый сервис можно обновлять отдельно.
    - **Независимая масштабируемость**: Нагруженный сервис (например, оплаты) можно масштабировать отдельно.
    - **Независимая деградация**: Сбой одного сервиса не ломает всю систему.
    - **Гибкость технологий**: Разные сервисы могут использовать разные языки/фреймворки.
- **Недостатки**:
    - **Зоопарк технологий**: Разнообразие языков и фреймворков усложняет поддержку.
    - **Сетевые вызовы**: Вызовы между сервисами медленнее локальных и могут отвалиться.
    - **Распределенность**: Сложно обеспечить консистентность данных (например, транзакции между сервисами).
    - **Сложность тестирования**: Нужно тестировать взаимодействие множества сервисов.
- **Пример**: Netflix использует микросервисы. Сервис рекомендаций, стриминга и биллинга независимы, что позволяет масштабировать их отдельно.
- **Когда использовать**: Для крупных систем с высокой нагрузкой, сложной логикой и большими командами.

### Резюме

- **Монолиты**: Идеальны для стартапов, прототипов и low-latency приложений.
- **Микросервисы**: Подходят для высоконагруженных систем, где важна гибкость и масштабируемость.
- **Аналогия**: Монолит — как одноэтажный дом, где все под рукой, но сложно расширять. Микросервисы — как жилой комплекс, где каждый блок автономен, но требует координации.


# Балансировка нагрузки и кэширование

## Балансировка нагрузки

Балансировка нагрузки — это процесс распределения входящего трафика между несколькими серверами (инстансами), чтобы обеспечить высокую доступность, масштабируемость и оптимальную производительность системы. Без балансировки нагрузки один сервер может стать узким местом, что приведёт к сбоям или задержкам.

### Типы балансировки нагрузки

#### 1. Клиентская балансировка

В клиентской балансировке клиентский код сам решает, на какой сервер отправить запрос, зная о доступных инстансах.

- **Как работает**: Клиент содержит список серверов (например, их IP-адреса) и использует алгоритм для выбора подходящего сервера (например, случайный выбор или по какому-то правилу).
- **Преимущества**:
    - Минимальная задержка (latency), так как нет промежуточного звена (балансировщика).
    - Простота для небольших систем.
- **Недостатки**:
    - Усложняет клиентский код, так как ему нужно знать о всех серверах и их состоянии.
    - Требуется постоянное обновление списка серверов на клиенте (например, при добавлении/удалении инстансов).
    - Сложно поддерживать и масштабировать, особенно в больших системах.
- **Пример**: Мобильное приложение напрямую выбирает сервер для запросов, используя список адресов, полученный при старте.
- **Аналогия**: Представьте, что вы сами выбираете, в какой кассе супермаркета стоять, основываясь на том, где меньше очередь. Это быстро, но требует от вас знать, как обстоят дела на всех кассах.

**Когда использовать**: Для небольших систем или в случаях, где важна минимальная задержка, и вы готовы мириться с дополнительной логикой на клиенте.

#### 2. Серверная балансировка

Серверная балансировка предполагает, что специальный компонент (балансировщик нагрузки) распределяет трафик между серверами. Это наиболее распространённый подход в современных системах.

- **Как работает**: Балансировщик (например, NGINX, HAProxy, AWS ELB) принимает входящие запросы и перенаправляет их на один из доступных серверов по определённому алгоритму.
- **Алгоритмы балансировки**:
    - **Random (Случайный выбор)**: Запросы распределяются случайно. Простой, но неэффективный подход, так как не учитывает состояние серверов.
    - **Round Robin**: Запросы распределяются по очереди на каждый сервер. Подходит для серверов с одинаковыми характеристиками.
    - **Weighted Round Robin**: Учитывает "вес" серверов (например, более мощный сервер получает больше запросов). Полезно, если серверы имеют разные технические характеристики.
    - **Least Connections**: Запросы отправляются на сервер с наименьшим количеством активных соединений. Хорошо работает для систем с длительными соединениями.
    - **Hash-based (Хеширование)**: Запросы распределяются на основе хеша (например, IP клиента или URL). Используется для sticky sessions (см. ниже).
- **Sticky Sessions (Липкие сессии)**:
    - Запросы от одного клиента всегда направляются на один и тот же сервер (например, по хешу IP или идентификатора сессии).
    - Полезно для stateful систем, где сервер хранит данные о сессии клиента.
    - Недостаток: Может привести к неравномерной нагрузке, если некоторые клиенты генерируют больше трафика.
- **Преимущества**:
    - Простота для клиента: он отправляет запросы на один адрес, а балансировщик решает, куда их направить.
    - Легко масштабировать: новые серверы добавляются в пул без изменений на клиенте.
    - Гибкость: можно использовать разные алгоритмы в зависимости от задачи.
- **Недостатки**:
    - Балансировщик — потенциальная точка отказа (см. DNS-балансировку ниже).
    - Может добавить небольшую задержку из-за обработки запросов.
- **Пример**: Веб-приложение использует NGINX как балансировщик, который распределяет запросы между несколькими серверами с помощью Round Robin. Если один сервер мощнее, применяется Weighted Round Robin.
- **Аналогия**: Балансировщик — как диспетчер в аэропорту, который направляет пассажиров к свободным стойкам регистрации, учитывая их загруженность.

**Когда использовать**: Для большинства современных систем, особенно высоконагруженных, где важна масштабируемость и простота управления.

#### 3. L4 и L7 балансировка

Балансировка может происходить на разных уровнях модели OSI: транспортном (L4) или прикладном (L7).

- **L4 (Транспортный уровень)**:
    
    - Работает с соединениями (например, TCP/UDP).
    - Балансировщик перенаправляет соединение целиком на один сервер, не анализируя содержимое запросов.
    - **Преимущества**:
        - Быстрее, так как не нужно разбирать содержимое запросов.
        - Простота реализации.
    - **Недостатки**:
        - Не видит содержимое запросов, поэтому не может принимать решения на основе данных (например, URL или заголовков).
        - Не поддерживает сложные сценарии, такие как маршрутизация по контенту.
    - **Пример**: Балансировщик L4 направляет TCP-соединение клиента на сервер базы данных, не зная, сколько запросов будет внутри.
    - **Аналогия**: L4-балансировщик — как почтальон, который доставляет посылку в дом, не зная, что внутри коробки.
- **L7 (Прикладной уровень)**:
    
    - Работает с содержимым запросов (например, HTTP-заголовки, URL, cookies).
    - Балансировщик анализирует запросы и распределяет их на основе содержимого.
    - **Преимущества**:
        - Гибкость: можно направлять запросы на разные серверы в зависимости от типа данных (например, видео на один сервер, текст — на другой).
        - Поддерживает sticky sessions, маршрутизацию по контенту и другие сложные сценарии.
    - **Недостатки**:
        - Медленнее, так как требуется разбор запросов до 7-го уровня и их повторная сборка.
        - Более высокая нагрузка на балансировщик.
    - **Пример**: L7-балансировщик в CDN направляет запросы на серверы, ближайшие к пользователю, или разделяет запросы к API и статическому контенту.
    - **Аналогия**: L7-балансировщик — как администратор ресторана, который смотрит на заказ клиента и решает, на какую кухню (итальянскую или азиатскую) его отправить.

**Когда использовать**: L4 для простых систем с низкой задержкой, L7 для сложных приложений, где важна маршрутизация по содержимому.

#### 4. DNS-балансировка

DNS-балансировка использует систему доменных имён (DNS) для распределения трафика между серверами или дата-центрами.

- **Как работает**:
    - DNS-сервер возвращает разные IP-адреса для одного домена, направляя клиентов на разные серверы.
    - Клиент сам выбирает один из адресов (например, с помощью Round Robin).
- **GeoDNS**:
    - DNS учитывает географическое положение клиента и направляет его на ближайший дата-центр.
    - Пример: Пользователь из США направляется в дата-центр в Нью-Йорке, а пользователь из Индии — в дата-центр в Мумбаи.
    - Это снижает задержку (latency), так как данные передаются по более короткому маршруту (например, из Москвы в Нью-Йорк задержка ~200 мс, а внутри региона — 20–50 мс).
- **Преимущества**:
    - Устраняет балансировщик как единую точку отказа, так как DNS распределяет трафик на уровне домена.
    - Подходит для распределённых систем с несколькими дата-центрами.
- **Недостатки**:
    - Ограниченный контроль: DNS не учитывает состояние серверов (например, их загруженность).
    - Кэширование DNS-записей на стороне клиента может привести к неравномерной нагрузке.
- **Пример**: Компания с дата-центрами в США и Индии использует GeoDNS, чтобы пользователи из разных регионов автоматически попадали на ближайший сервер.
- **Аналогия**: DNS-балансировка — как указатель на дороге, который направляет водителей в разные города. GeoDNS — это указатель, который знает, откуда вы едете, и направляет вас в ближайший город.

**Когда использовать**: Для глобальных систем с несколькими дата-центрами или для устранения единой точки отказа балансировщика.

### Проблема единой точки отказа

Балансировщик нагрузки может стать единой точкой отказа (single point of failure, SPOF). Если он выходит из строя, вся система становится недоступной.

- **Решение**:
    - Использовать несколько балансировщиков с DNS-балансировкой.
    - Настроить отказоустойчивость (например, резервные балансировщики в режиме active-passive).
    - Применять GeoDNS для распределения трафика между дата-центрами.
- **Пример**: В крупной системе, как у Яндекса, на входе стоят несколько L4-балансировщиков, которые распределяют трафик между дата-центрами, а внутри каждого дата-центра L7-балансировщики (например, NGINX) распределяют запросы между серверами.
- **Аналогия**: Если один мост (балансировщик) ломается, вы строите несколько мостов и указываете водителям (DNS), как до них добраться.

---

## Кэширование

Кэширование — это техника хранения часто используемых данных в быстром хранилище (кэше) для ускорения ответов, снижения нагрузки на сторонние сервисы и стабилизации работы системы при кратковременных сбоях.

### Зачем нужно кэширование?

1. **Сокращение времени ответа (response time)**:
    - Доступ к кэшу (например, Redis) занимает 10–20 мс, тогда как к базе данных — 50–100 мс.
    - Пример: В соцсети кэширование ленты постов ускоряет загрузку страниц.
2. **Снижение нагрузки на сторонние сервисы**:
    - Кэш принимает на себя запросы на чтение, позволяя базе данных обрабатывать только записи или сложные запросы.
    - Пример: В e-commerce кэш хранит каталог товаров, чтобы база данных не перегружалась.
3. **Стабилизация работы при сбоях**:
    - Если сторонний сервис (например, API курсов валют) временно недоступен, кэш может отдавать старые данные.
    - Пример: Сервис конвертации валют кэширует курсы раз в минуту. Если API валют недоступен, система продолжает работать с последними данными.
4. **Экономия ресурсов**:
    - Кэширование результатов ресурсоёмких вычислений (например, сложных математических расчётов) позволяет избежать их повторного выполнения.
    - Пример: Сервис машинного обучения кэширует результаты предсказаний для одинаковых входных данных.

**Аналогия**: Кэш — как холодильник с готовой едой. Вместо того чтобы каждый раз готовить (обращаться к базе данных), вы берёте готовое блюдо (данные из кэша).

### Термины кэширования

- **Cache Hit (Попадание в кэш)**: Запрошенные данные найдены в кэше.
- **Cache Miss (Промах кэша)**: Данные отсутствуют в кэше, и система обращается к базе данных.
- **Hit Rate (Процент попаданий)**: Доля запросов, которые были обслужены кэшем (например, 80% hit rate означает, что 80% запросов нашли данные в кэше).
- **Hot Key (Горячий ключ)**: Ключ, к которому чаще всего обращаются. Например, страница популярного блогера в соцсети (с 600 млн подписчиков) будет горячим ключом.
- **Cache Warmup (Прогрев кэша)**: Процесс заполнения кэша данными после его запуска или очистки. Может быть постепенным (реальный трафик) или активным (тестовые данные).
- **Cache Invalidation (Инвалидация кэша)**: Удаление устаревших данных из кэша, чтобы они обновились из базы данных.

**Пример**: В YouTube страница популярного видео — горячий ключ, который всегда находится в кэше. При запуске нового сервера кэш прогревается, чтобы избежать лавины запросов к базе данных.

### Проблемы кэширования

- **Атаки на промахи кэша**:
    - Хакеры могут отправлять запросы к данным, которых нет в кэше, чтобы перегрузить базу данных.
    - Пример: Запросы к редко посещаемым профилям в соцсети, которые не кэшируются, могут перегрузить базу данных.
- **Распространённая ошибка**:
    - Разработчики используют кэш как основное средство для обработки всей нагрузки на чтение.
    - Если кэш выходит из строя или имеет высокий процент промахов, база данных не справляется.
- **Решение**:
    - Кэш должен **ускорять ответы**, а не заменять базу данных.
    - Кэш должен **поддерживать базу данных**, а не быть единственным источником данных.
    - Нужны **стратегии повторного кэширования** (например, прогрев кэша после сбоя).
- **Формула эффективности кэша**:
    - Время доступа к базе данных = 100 мс.
    - Время доступа к кэшу = 20 мс.
    - Среднее время доступа = (Hit Rate × Время кэша) + (Miss Rate × Время базы).
    - Если Miss Rate > 80% (0.8), среднее время доступа превысит 100 мс, и кэш становится неэффективным.
    - В таком случае лучше полагаться только на базу данных.
- **Метрики**:
    - **Latency**: Время обработки одного запроса (например, 20 мс для кэша).
    - **Response Time**: Полное время ответа, включая сетевые задержки.
    - Обычно используют response time, но обе метрики важны.

**Пример**: В банковской системе высокий процент промахов кэша (например, 90%) делает его бесполезным, так как запросы всё равно идут в базу данных, увеличивая задержку.

### Виды кэширования

#### 1. Внешнее кэширование

Данные хранятся во внешнем хранилище (например, Redis, Memcached), отдельном от сервиса.

- **Преимущества**:
    - Легко масштабировать: новые инстансы сервиса подключаются к общему кэшу.
    - Данные сохраняются после рестарта сервиса.
    - Упрощает логику прогрева и инвалидации кэша.
    - Подходит для больших объёмов данных, так как кэш оптимизирован по ресурсам.
- **Недостатки**:
    - Сетевые задержки при обращении к кэшу.
    - Требуется сериализация/десериализация данных (маршалинг/анмаршалинг), что добавляет накладные расходы.
- **Пример**: В интернет-магазине Redis хранит каталог товаров, доступный для всех серверов.
- **Аналогия**: Внешний кэш — как центральный склад, где все магазины берут товары, но доставка занимает время.

#### 2. Внутреннее кэширование

Данные хранятся в памяти самого сервиса (например, в виде хэш-таблицы или дерева).

- **Преимущества**:
    - Высокая скорость доступа, так как нет сетевых запросов.
    - Нет накладных расходов на сериализацию данных.
- **Недостатки**:
    - Сложности с горизонтальным масштабированием: каждый инстанс хранит свой кэш.
    - Данные теряются при рестарте сервиса, требуется прогрев кэша.
- **Пример**: Внутренний кэш в Go-приложении использует map для хранения часто запрашиваемых данных, таких как настройки.
- **Аналогия**: Внутренний кэш — как личный блокнот, который всегда под рукой, но доступен только вам.

**Решение проблемы масштабирования**: Для внутреннего кэширования можно использовать структуры данных, такие как map, деревья или векторы, в зависимости от задачи. Однако для обеспечения консистентности между инстансами лучше использовать внешний кэш.

### Кэширование ошибок

Можно кэшировать не только данные, но и их отсутствие, чтобы избежать повторных запросов к базе данных.

- **Пример**: Пользователь запрашивает профиль с ID 5, которого нет в базе данных. Вместо того чтобы каждый раз проверять базу, кэш сохраняет информацию "ID 5 не существует" на заданное время (например, 5 секунд).
- **Аналогия**: Если вы знаете, что в холодильнике нет молока, вы не будете каждый раз открывать дверцу, а запомните это на какое-то время.

### Консистентность и выбор данных для кэширования

- **Какие данные кэшировать**:
    - Данные, которые редко меняются (например, каталог товаров или настройки).
    - Результаты ресурсоёмких вычислений (например, предсказания ML-модели).
- **Какие данные не кэшировать**:
    - Часто меняющиеся данные (например, биржевые котировки, обновляющиеся каждую секунду).
    - Если данные меняются часто (например, каждые несколько секунд), кэширование может быть неэффективным из-за необходимости частой инвалидации.
- **Компромиссы**:
    - Иногда бизнес готов пожертвовать консистентностью ради производительности. Например, кэширование курсов валют с обновлением раз в минуту допустимо, если пользователи не заметят разницы.
    - Решение о кэшировании зависит от **hit rate** и требований бизнеса.
- **Пример**: В системе логов данные пишутся часто, но редко читаются, поэтому кэширование может быть неэффективным. В соцсети же посты читаются часто, и кэш значительно снижает нагрузку.

### Архитектурные паттерны для кэширования

- **Blue-Green Deployment**:
    - Используется для минимизации простоев при обновлении сервисов или кэша.
    - Один кластер (blue) обрабатывает трафик, пока второй (green) обновляется и прогревает кэш. После готовности трафик переключается на green.
    - Пример: Обновление сервера в стриминговом сервисе с прогревом кэша перед переключением.
- **Прогрев кэша**:
    - Постепенное заполнение кэша реальным трафиком или тестовыми данными.
    - Пример: Новый сервер в e-commerce сначала получает 10% трафика, чтобы заполнить кэш, прежде чем взять полную нагрузку.

### Атаки на промахи кэша

- **Как работают**: Хакеры отправляют запросы к данным, которых нет в кэше, чтобы перегрузить базу данных.
- **Почему опасно**: Если кэш обрабатывает всю нагрузку, а база данных не готова к ней, система выходит из строя.
- **Решение**:
    - Ограничивать частоту запросов (rate limiting).
    - Использовать прогрев кэша и стратегии инвалидации.
    - Проектировать базу данных так, чтобы она могла выдержать часть нагрузки.
- **Пример**: В соцсети злоумышленник запрашивает профили несуществующих пользователей, вызывая промахи кэша. Rate limiting блокирует такие атаки.

**Аналогия**: Атака на промахи кэша — как заказ в ресторане блюд, которых нет в меню. Если повар (база данных) не готов к таким заказам, кухня останавливается.



# Взаимодействие с кэшем и алгоритмы вытеснения

## Взаимодействие с кэшем

Кэширование — важный инструмент для оптимизации производительности систем, но его эффективность зависит от правильного выбора стратегии взаимодействия с кэшем. Разные подходы к чтению и записи данных в кэш решают различные задачи, такие как снижение задержки, обеспечение консистентности или упрощение архитектуры. Выбор подхода зависит от соотношения операций чтения и записи, требований к консистентности и характера нагрузки.

### Основные подходы к взаимодействию с кэшем

#### 1. Ленивое кэширование (Cache-Aside)

- **Как работает**:
    - Сервис сначала обращается к кэшу.
    - Если данные есть (cache hit), они возвращаются сразу.
    - Если данных нет (cache miss), сервис запрашивает их из базы данных (БД), сохраняет в кэш и возвращает клиенту.
- **Преимущества**:
    - Простота реализации.
    - Кэш заполняется только по мере необходимости, экономя ресурсы.
- **Недостатки**:
    - При cache miss запросы медленные, так как требуется обращение к БД.
    - Может возникнуть гонка (race condition), если несколько запросов одновременно пытаются заполнить кэш.
- **Пример**: В интернет-магазине кэш (Redis) хранит информацию о товарах. Если товар отсутствует в кэше, сервис запрашивает его из PostgreSQL и сохраняет в Redis.
- **Аналогия**: Ленивое кэширование — как записная книжка, в которую вы добавляете номер телефона только после того, как вам пришлось его искать в справочнике.

**Когда использовать**: Для систем с read-heavy нагрузкой, где данные редко меняются (например, каталоги товаров или справочные данные).

#### 2. Запись в кэш после базы данных (Write-Through)

- **Как работает**:
    - Данные сначала записываются в базу данных, а затем синхронно обновляются в кэше.
    - Кэш всегда содержит актуальные данные.
- **Преимущества**:
    - Гарантирует консистентность между кэшем и БД.
    - Упрощает чтение, так как данные в кэше всегда актуальны.
- **Недостатки**:
    - Увеличивает задержку записи, так как нужно обновлять два хранилища.
    - Может быть избыточным, если данные редко читаются.
- **Пример**: В банковской системе при обновлении баланса транзакция сначала записывается в БД, а затем в кэш, чтобы последующие запросы на чтение были быстрыми.
- **Аналогия**: Это как обновление и основного архива, и вашей записной книжки каждый раз, когда меняется чей-то номер телефона.

**Когда использовать**: Когда важна высокая консистентность данных (например, в финансовых системах).

#### 3. Сквозное кэширование (Cache-Through)

- **Как работает**:
    - Все запросы проходят через кэш, а приложение не взаимодействует напрямую с БД.
    - Если данных нет в кэше, кэш сам запрашивает их из БД и сохраняет.
    - Логика взаимодействия с БД инкапсулирована в кэше.
- **Преимущества**:
    - Упрощает логику приложения, так как оно работает только с кэшем.
    - Снижает сложность кода сервиса.
- **Недостатки**:
    - Если кэш выходит из строя, приложение теряет доступ к данным.
    - Требуется механизм автоматического обновления кэша из БД.
- **Пример**: В стриминговом сервисе кэш (например, Memcached) обрабатывает все запросы к метаданным видео, а при промахах сам запрашивает данные из БД.
- **Аналогия**: Сквозное кэширование — как библиотекарь, который сам ищет книгу в хранилище, если её нет на полке, а вы просто ждёте результат.

**Когда использовать**: Для систем, где важна простота кода приложения, и есть механизмы для восстановления кэша.

#### 4. Опережающее кэширование (Write-Ahead/Read-Through)

- **Как работает**:
    - Запросы на чтение идут только в кэш.
    - Данные периодически загружаются в кэш из БД (например, по расписанию или по событиям).
- **Преимущества**:
    - Минимальная задержка (latency), так как запросы не доходят до БД.
    - Подходит для систем, где важна высокая скорость чтения.
- **Недостатки**:
    - Возможна неконсистентность, если данные в БД изменились, а кэш ещё не обновился.
    - Требуется механизм периодического обновления кэша.
- **Пример**: В системе курсов валют кэш обновляется раз в минуту, и все запросы клиентов обслуживаются из кэша, даже если данные немного устарели.
- **Аналогия**: Это как доска объявлений, которую обновляют раз в час. Вы читаете только её, даже если информация слегка устарела.

**Когда использовать**: Когда низкая задержка важнее консистентности (например, в системах отображения новостей или статистики).

#### 5. Асинхронная запись (Write-Back)

- **Как работает**:
    - Данные сначала записываются в кэш, а затем асинхронно (пакетами) отправляются в БД.
    - Можно использовать компактизацию: если несколько операций изменяют один объект, устаревшие изменения отбрасываются.
- **Преимущества**:
    - Снижает нагрузку на БД, так как записи группируются.
    - Ускоряет операции записи для клиента.
- **Недостатки**:
    - Риск потери данных, если кэш выходит из строя до синхронизации с БД.
    - Требуется сложная логика синхронизации.
- **Пример**: В системе логов данные сначала пишутся в кэш (например, Redis), а воркер периодически переносит их в БД (например, ClickHouse).
- **Аналогия**: Это как записывать заказы в блокнот, а в конце дня переносить их в учётную систему. Если блокнот потеряется, часть заказов может пропасть.

**Когда использовать**: Для write-heavy систем, где важна скорость записи, а кратковременная неконсистентность допустима.

### Как выбрать подход?

- **Актуализация данных**: Если данные редко меняются (например, каталог товаров), подойдёт ленивое или опережающее кэширование. Если важна консистентность (например, баланс счёта), используйте write-through.
- **Соотношение чтения/записи**: Для read-heavy систем (соцсети) лучше ленивое или сквозное кэширование. Для write-heavy (логи) — асинхронная запись.
- **Отказоустойчивость**: Убедитесь, что приложение может работать, если кэш недоступен. Например, в сквозном кэшировании нужен механизм обращения к БД при сбое кэша.
- **Пример**: В e-commerce для каталога товаров используется ленивое кэширование, а для транзакций — write-through, чтобы гарантировать консистентность.

**Аналогия**: Выбор подхода к кэшированию — как выбор способа доставки еды. Если нужна скорость (опережающее кэширование), вы берёте готовую еду из холодильника. Если важна свежесть (write-through), вы готовите еду на заказ, но это дольше.

---

## Алгоритмы вытеснения данных из кэша

Кэш имеет ограниченный объём памяти, и, когда он заполняется, нужно решать, какие данные удалить, чтобы освободить место для новых. Алгоритмы вытеснения определяют, какой элемент кэша будет удалён.

### Почему нужны алгоритмы вытеснения?

- Кэш обычно значительно меньше базы данных. Например, база данных может быть на петабайты, а кэш — на гигабайты.
- Когда кэш заполнен (например, хранит данные о 4 пользователях), а нужно добавить новый элемент (user5), один из существующих элементов должен быть вытеснен.
- Выбор алгоритма влияет на hit rate и производительность системы.

**Пример**: В кэше Redis размером 1 ГБ хранятся данные о пользователях. При добавлении нового пользователя, если места нет, старый элемент удаляется по алгоритму вытеснения.

**Аналогия**: Кэш — как шкаф с ограниченным числом полок. Если вы хотите добавить новую книгу, нужно убрать одну из старых. Алгоритм вытеснения решает, какую именно.

### Основные алгоритмы вытеснения

#### 1. Random (Случайное вытеснение)

- **Как работает**: Удаляется случайный элемент из кэша.
- **Преимущества**:
    - Простота реализации.
    - Подходит для тестирования или систем с низкими требованиями.
- **Недостатки**:
    - Неэффективно, так как может удалить часто используемые данные.
    - Низкий hit rate.
- **Пример**: Кэш случайно удаляет профиль популярного пользователя, что приводит к промаху при следующем запросе.
- **Аналогия**: Вы случайным образом выбрасываете книгу из шкафа, даже если она популярна.

**Когда использовать**: Только для тестов или систем, где hit rate не критичен.

#### 2. FIFO (First In, First Out — Первый вошёл, первый вышел)

- **Как работает**: Удаляется элемент, который был добавлен в кэш раньше всех.
- **Преимущества**:
    - Простота реализации (аналог очереди).
    - Подходит для данных с равномерным доступом.
- **Недостатки**:
    - Не учитывает частоту использования данных.
    - Может удалить популярные данные, если они были добавлены давно.
- **Пример**: Кэш хранит user1, user2, user3, user4. При добавлении user5 удаляется user1, даже если он активно используется.
- **Аналогия**: FIFO — как очередь в магазине. Первый пришёл — первый ушёл, независимо от того, насколько важный клиент.

**Когда использовать**: Для данных с предсказуемым жизненным циклом, где старые данные менее актуальны.

#### 3. LIFO (Last In, First Out — Последний вошёл, первый вышел)

- **Как работает**: Удаляется последний добавленный элемент.
- **Преимущества**:
    - Простота реализации.
    - Может быть полезно в специфических сценариях (например, временные данные).
- **Недостатки**:
    - Редко используется, так как новые данные часто более востребованы.
    - Низкий hit rate в большинстве случаев.
- **Пример**: Кэш удаляет только что добавленного user5, хотя он может быть горячим ключом.
- **Аналогия**: LIFO — как стопка тарелок. Вы убираете верхнюю (последнюю добавленную), даже если она нужна.

**Когда использовать**: Для временных данных, где старые элементы важнее новых.

#### 4. LRU (Least Recently Used — Наименее недавно использованный)

- **Как работает**: Удаляется элемент, к которому дольше всего не было обращений.
- **Преимущества**:
    - Высокий hit rate, так как сохраняет часто используемые данные.
    - Хорошо подходит для систем с горячими ключами.
- **Недостатки**:
    - Требует дополнительной памяти для отслеживания времени последнего доступа.
    - Более сложная реализация (например, с использованием связного списка и хэш-таблицы).
- **Пример**: В кэше хранятся user1, user2, user3, user4. Если недавно обращались к user1, а user2 не трогали дольше всех, то user2 вытесняется.
- **Аналогия**: LRU — как библиотека, где вы убираете книгу, которую никто давно не брал, чтобы освободить место для новой.

**Когда использовать**: Для большинства современных систем, особенно с read-heavy нагрузкой и горячими ключами (например, соцсети, e-commerce).

#### 5. MRU (Most Recently Used — Наиболее недавно использованный)

- **Как работает**: Удаляется элемент, к которому только что обращались.
- **Преимущества**:
    - Может быть полезно в редких сценариях, где данные используются однократно.
- **Недостатки**:
    - Низкий hit rate, так как удаляет недавно запрошенные данные.
- **Пример**: После обращения к user1 он сразу вытесняется, что неэффективно для большинства систем.
- **Аналогия**: MRU — как выбрасывание только что прочитанной книги, что редко имеет смысл.

**Когда использовать**: Для специфических случаев, где данные используются один раз (например, одноразовые токены).

#### 6. LFU (Least Frequently Used — Наименее часто используемый)

- **Как работает**: Удаляется элемент, который реже всего запрашивали.
- **Преимущества**:
    - Эффективно для систем с чётко выраженными горячими ключами.
    - Учитывает долгосрочную популярность данных.
- **Недостатки**:
    - Требует подсчёта частоты обращений, что увеличивает сложность.
    - Может быть неэффективно, если популярность данных быстро меняется.
- **Пример**: Если user1 запрашивали 100 раз, а user2 — только 5, то user2 вытесняется.
- **Аналогия**: LFU — как уборка в шкафу, где вы выбрасываете одежду, которую редко носите.

**Когда использовать**: Для систем с устойчивыми горячими ключами, где важно сохранять популярные данные.

### Как выбрать алгоритм вытеснения?

- **LRU**: Стандартный выбор для большинства систем, так как хорошо работает с горячими ключами.
- **LFU**: Подходит, если важна долгосрочная популярность данных.
- **FIFO**: Для простых систем с предсказуемым жизненным циклом данных.
- **Random/MRU/LIFO**: Редко используются, только для специфических случаев или тестирования.
- **Пример**: В YouTube для кэширования метаданных популярных видео используется LRU, так как горячие ключи (видео с миллионами просмотров) должны оставаться в кэше.

**Аналогия**: Выбор алгоритма вытеснения — как выбор, какую коробку выбросить из полного гаража. LRU убирает то, что давно не трогали, а LFU — то, что редко использовали.

### Кэширование в системах с репликацией (Master-Slave)

- В системах с репликацией (например, master для записи, slave для чтения) можно использовать разные стратегии кэширования для разных баз:
    - Для slave (read-heavy): Ленивое или сквозное кэширование, чтобы ускорить чтение.
    - Для master (write-heavy): Write-through или асинхронная запись, чтобы снизить нагрузку на запись.
- **Пример**: В банковской системе master обрабатывает транзакции с write-through кэшированием, а slave использует ленивое кэширование для отображения баланса.
- **Аналогия**: Master — как главный повар, который готовит блюда (записи), а slave — как официант, который быстро разносит готовые блюда (чтение) из холодильника (кэша).

**Примечание**: Подробно про репликацию говорить не будем, так как это запланировано на третье занятие.

---

## Дополнительные аспекты

- **Worker для асинхронного кэширования**:
    - В некоторых системах используется воркер, который периодически вычитывает данные из кэша и синхронизирует их с БД.
    - Пример: В системе аналитики воркер раз в минуту переносит агрегированные данные из Redis в ClickHouse.
    - **Аналогия**: Worker — как уборщик, который раз в час проверяет, что нужно перенести из временного хранилища в постоянное.
- **Отказоустойчивость**:
    - Убедитесь, что приложение может работать без кэша (например, напрямую с БД).
    - Используйте механизмы мониторинга (Prometheus) и rate limiting для защиты от атак на промахи кэша.
- **Консистентность vs производительность**:
    - Иногда бизнес готов пожертвовать консистентностью ради скорости. Например, в системе курсов валют допустима задержка обновления кэша на минуту.
    - Решение зависит от hit rate и требований к актуальности данных.



# Продвинутые алгоритмы вытеснения кэша

## Алгоритмы вытеснения кэша: Продвинутые подходы

Кэш имеет ограниченный объём памяти, и алгоритмы вытеснения данных определяют, какие элементы удалять, когда места не хватает. В предыдущем разделе мы рассмотрели базовые алгоритмы (Random, FIFO, LIFO, LRU, MRU, LFU). Теперь разберём более сложные алгоритмы, такие как Second Chance, Clock, 2Q и теоретический OPT (алгоритм Беллади), а также их применение в реальных системах, включая базы данных и виртуальную память.

### Выбор алгоритма вытеснения

Выбор алгоритма зависит от характера обращений к данным и требований бизнеса:

- **Частые обращения к свежим данным**: LRU (Least Recently Used) подходит, так как сохраняет недавно использованные элементы.
- **Частые обращения к одним и тем же данным**: LFU (Least Frequently Used) эффективен, так как учитывает частотность.
- **Вероятность обращения к давно неиспользуемым данным**: MRU (Most Recently Used) может быть полезен, если старые данные становятся актуальными.
- **Пример**: В соцсети, где пользователи часто смотрят свежие посты, LRU сохраняет новые данные в кэше. В аналитической системе, где запрашиваются одни и те же отчёты, LFU лучше подходит для сохранения популярных данных.
- **Аналогия**: Выбор алгоритма — как организация полок в библиотеке. Если читатели берут новые книги, вы держите их ближе (LRU). Если одни и те же книги популярны, вы сохраняете их на видном месте (LFU).

### Применение в реальных системах

- **Базы данных**: Используют **page cache** (пейдж-кэш) для хранения часто запрашиваемых страниц данных. Например, PostgreSQL или MySQL применяют алгоритмы вытеснения, чтобы управлять ограниченной памятью.
- **Виртуальная память в ОС**: В Linux, например, для свопинга страниц между оперативной памятью и диском используются алгоритмы вытеснения, такие как Second Chance или Clock.
- **Пример**: В базе данных page cache хранит индексы или часто запрашиваемые строки. Если памяти не хватает, алгоритм вытеснения решает, какую страницу выгрузить на диск.

**Аналогия**: Page cache в базе данных или виртуальная память — как рабочий стол, где вы держите только самые нужные документы. Если стол заполнен, вы убираете менее важные бумаги в шкаф.

### Продвинутые алгоритмы вытеснения

#### 1. OPT (Оптимальный алгоритм Беллади)

- **Как работает**:
    - Теоретический алгоритм, который вытесняет элемент, к которому дольше всего не будет обращений в будущем.
    - Для реализации требуется знать будущее поведение запросов (например, через сколько секунд или минут к элементу обратятся).
- **Преимущества**:
    - Максимальный hit rate, так как всегда вытесняется наименее нужный элемент.
- **Недостатки**:
    - Нереализуем на практике, так как невозможно точно предсказать будущие обращения.
    - Может использоваться как эталон для сравнения других алгоритмов.
- **Пример**: Если кэш хранит user1 (обращение через 10 с), user2 (5 с), user3 (3 мин), OPT вытеснит user3, так как к нему обратятся позже всех.
- **Аналогия**: OPT — как ясновидящий библиотекарь, который знает, какую книгу никто не возьмёт в ближайшие часы, и убирает её с полки.

**Когда использовать**: Только для теоретического анализа или исследований (например, с использованием ML для прогнозирования обращений).

#### 2. Second Chance

- **Как работает**:
    - Усовершенствованная версия FIFO. Каждый элемент имеет флаг `used` (булевый бит), который указывает, обращались ли к элементу.
    - Элементы хранятся в очереди. При необходимости вытеснения проверяется первый элемент:
        - Если `used = true`, флаг сбрасывается (`used = false`), и элемент перемещается в конец очереди (даётся "второй шанс").
        - Если `used = false`, элемент вытесняется.
    - Если у всех элементов `used = true`, алгоритм проходит по очереди, сбрасывая флаги, пока не найдёт элемент для вытеснения.
- **Преимущества**:
    - Даёт шанс часто используемым элементам остаться в кэше.
    - Прост в реализации по сравнению с LRU.
- **Недостатки**:
    - Если все элементы имеют `used = true`, алгоритм может деградировать до FIFO, перебирая всю очередь.
- **Пример**: Кэш хранит user1, user2, user3, user4. Обращаются к user1, его `used = true`. При добавлении user5 проверяется user1: так как `used = true`, он перемещается в конец, а следующий элемент (user2) проверяется.
- **Аналогия**: Second Chance — как очередь в кафе, где постоянным клиентам дают шанс остаться, перемещая их в конец, если они недавно заказывали.

**Когда использовать**: В системах, где нужно сбалансировать простоту FIFO и эффективность LRU (например, в виртуальной памяти Linux).

#### 3. Clock (Часовой алгоритм)

- **Как работает**:
    - Улучшение Second Chance, использующее циклический буфер (circular buffer) вместо перемещения элементов.
    - Элементы хранятся в кольцевой структуре с указателем. Каждый элемент имеет флаг `used`.
    - При необходимости вытеснения указатель движется по кругу:
        - Если `used = true`, флаг сбрасывается, и указатель движется дальше.
        - Если `used = false`, элемент вытесняется.
- **Преимущества**:
    - Устраняет накладные расходы на перемещение элементов, как в Second Chance.
    - Эффективен для систем с ограниченными ресурсами.
- **Недостатки**:
    - Как и Second Chance, может деградировать до FIFO при высокой активности.
- **Пример**: В Linux Clock используется для управления страницами в виртуальной памяти. Если страница недавно использовалась, она получает шанс остаться.
- **Аналогия**: Clock — как циферблат часов, где указатель обходит элементы. Если элемент "активен", он остаётся, иначе вытесняется.

**Когда использовать**: В системах с ограниченными ресурсами, где нужно минимизировать операции с памятью (например, в ОС или базах данных).

#### 4. 2Q (Two Queues)

- **Как работает**:
    - Использует две FIFO-очереди (A1 и A2) и одну LRU-очередь.
    - Новая вставка идёт в первую FIFO (A1, "отстойник").
    - Если элемент вытесняется из A1, он перемещается во вторую FIFO (A2).
    - Если к элементу в A2 обращаются, он перемещается в LRU-очередь.
    - Вытеснение:
        - Из A1: по алгоритму FIFO.
        - Из A2: по алгоритму FIFO, если нет обращений.
        - Из LRU: по алгоритму LRU.
- **Преимущества**:
    - Позволяет "прогреть" данные в A1, прежде чем они станут горячими ключами в LRU.
    - Сбалансирует прогрев кэша и эффективность LRU.
- **Недостатки**:
    - Более сложная реализация.
    - Требует настройки размеров очередей.
- **Пример**: В веб-приложении 2Q используется для кэширования страниц. Новые страницы сначала попадают в A1, а популярные переходят в LRU.
- **Аналогия**: 2Q — как фильтр в кофейне. Новые клиенты (A1) ждут в очереди. Если они возвращаются (A2), их обслуживают быстрее. Постоянные клиенты (LRU) получают приоритет.

**Когда использовать**: Когда нужно сбалансировать прогрев кэша и сохранение горячих ключей (например, в высоконагруженных веб-приложениях).

#### 5. SLRU (Segmented LRU)

- **Как работает**:
    - Кэш делится на уровни: холодный (cold), тёплый (warm) и горячий (hot).
    - Элементы начинаются в cold LRU. При обращении переходят в warm LRU, затем в hot LRU.
    - Вытеснение:
        - Из cold LRU: элементы удаляются чаще.
        - Из hot LRU: элементы удаляются реже, так как они самые популярные.
- **Преимущества**:
    - Комбинирует LRU и LFU, учитывая и недавность, и частотность обращений.
    - Эффективен для систем с чётко выраженными горячими ключами.
- **Недостатки**:
    - Сложность реализации и настройки размеров сегментов.
- **Пример**: В стриминговом сервисе SLRU хранит метаданные популярных видео в hot LRU, а редко запрашиваемые — в cold LRU.
- **Аналогия**: SLRU — как гардероб с тремя полками: нижняя для редко используемых вещей, средняя для повседневных, верхняя для любимых.

**Когда использовать**: Когда нужно совместить преимущества LRU и LFU (например, в базах данных или CDN).

#### 6. TTL-based LRU (Time-based LRU)

- **Как работает**:
    - Элементы вытесняются не только по размеру кэша, но и по времени жизни (TTL, time-to-live).
    - Если TTL истёк, элемент удаляется, даже если кэш не заполнен.
- **Преимущества**:
    - Простота реализации.
    - Подходит для данных с чётким сроком актуальности.
- **Недостатки**:
    - Не учитывает частоту обращений, если TTL ещё не истёк.
- **Пример**: В кэше Redis для сессий пользователей установлен TTL 30 минут. Даже если сессия активна, она удаляется по истечении времени.
- **Аnalогия**: TTL-based LRU — как продукты в холодильнике с истекающим сроком годности. Даже если вы их любите, они выбрасываются, когда просрочены.

**Когда использовать**: Для данных с ограниченным сроком актуальности (например, сессии, временные токены).

#### 7. LRU-K

- **Как работает**:
    - Удаляет элементы на основе времени их K-го последнего доступа.
    - LRU-1 — это обычный LRU (удаляет по последнему доступу).
    - LRU-2 удаляет по предпоследнему доступу, LRU-3 — по предпредпоследнему, и т.д.
- **Преимущества**:
    - Уменьшает влияние случайных обращений, фокусируясь на долгосрочной активности.
- **Недостатки**:
    - Сложная реализация, так как нужно отслеживать историю доступов.
    - Редко используется на практике из-за специфичности.
- **Пример**: В аналитической системе LRU-2 может вытеснять отчёты, к которым давно не обращались, игнорируя случайные запросы.
- **Аналогия**: LRU-K — как выбор, какую книгу убрать с полки, основываясь не на последнем чтении, а на предпоследнем, чтобы избежать импульсивных решений.

**Когда использовать**: Для специфических случаев, где важна история обращений, а не последние запросы.

### Проблемы и ограничения

- **Second Chance/Clock**:
    - Если все элементы имеют `used = true`, алгоритм деградирует до FIFO, перебирая очередь.
    - Clock решает проблему перемещения элементов, используя циклический буфер.
- **2Q**:
    - Требует настройки размеров очередей A1 и A2.
    - Сложнее в реализации, чем LRU.
- **SLRU**:
    - Требует балансировки размеров сегментов (cold, warm, hot).
- **OPT**:
    - Нереализуем на практике, так как требует предсказания будущих обращений.
    - Может использоваться для моделирования или ML-прогнозов, но это дорого и сложно.

### Применение в реальных системах

- **Linux**: Использует Clock и Second Chance для управления виртуальной памятью. Страницы, к которым недавно обращались, получают второй шанс, чтобы остаться в памяти.
- **Базы данных**: Page cache в PostgreSQL или MySQL применяет LRU или SLRU для хранения горячих данных.
- **Кэши**: Redis поддерживает LRU и TTL-based вытеснение, а Memcached — LRU.
- **Пример**: В YouTube кэш метаданных видео использует SLRU, чтобы держать популярные видео в hot LRU, а новые — в cold LRU.

**Аналогия**: Алгоритмы вытеснения в реальных системах — как менеджер склада, решающий, какие коробки оставить на виду, а какие убрать в дальний угол, основываясь на их популярности или свежести.

### Как выбрать алгоритм?

- **LRU**: Универсальный выбор для большинства систем с горячими ключами.
- **LFU**: Для систем, где важна частотность (например, аналитика).
- **Second Chance/Clock**: Для систем с ограниченными ресурсами (например, ОС).
- **2Q/SLRU**: Для сложных систем, где нужно сбалансировать прогрев кэша и сохранение популярных данных.
- **TTL-based**: Для данных с чётким сроком жизни.
- **LRU-K**: Для редких случаев, где важна история обращений.

**Пример**: В e-commerce LRU используется для кэширования каталога товаров, так как пользователи часто запрашивают популярные позиции. В системе логов 2Q может быть полезен, чтобы новые данные сначала "прогревались" в A1, прежде чем стать горячими в LRU.





Апишка, апи. Давайте рассмотрим, какие способы есть. 

Сначала есть такая штука, как CRUD - акроним, обозначающий четыре базовые операции, которые, как правило, присутствуют:
1. Создать (Create)
2. Прочитать (Read)
3. Модифицировать (Update)
4. Удалить (Delete)

Вот эти операции можно описать с помощью акронима CRUD. Есть официальные случаи, когда нужно чего-то получить, отменить и так далее. Но можно всё это описать.

Теперь говорим о протоколе и способах структурирования. То, что мы будем рассматривать, не будет работать на поверхности. Я не буду углубляться в версии протоколов, таких как HTTP/1.1, HTTP/2 и так далее. Интересно, ознакомиться можно, но мы будем говорить именно о концепциях, как использовать этот протокол.

Протокол можно использовать по-разному — можно использовать JSON, XML и передавать текст. Рассмотрим, как можно использовать REST. У меня есть глаголы: GET, POST и другие. У меня есть уникальный идентификатор ресурса и существительное. По сути, я делаю какое-то действие с существительным при помощи глагола.

Еслиим статус-коды, то я получаю результаты. Если всё прошло успешно, мы получаем коды 200, 300, 400, 500.Есть концепция, которая устарела и практически не используется, но есть много легаси-проектов, где это присутствует. Я бы не стал углубляться в SOAP из-за многословности и больших объемов данных. JSON занимает меньше места, поэтому стал более предпочтительным. В результате XML был вытеснен.

Также есть концепция, как RPC. Когда пользователь вызывает функцию, под капотом происходит сетевой вызов к другому сервису. Идея в том, что код становится проще, не нужно дергать адреса. Например, часто используется gRPC, который упрощает процессы.

У меня есть тело запроса и ответа. Я не задумываюсь о том, как сконфигурировано тело ответа, всё парсится автоматически Я просто вызываю метод.

В основе работы лежит протокол, который компилирует запросы, и формирует исходный код для их обработки.


исходный код, который реализует это всё, вызывает методы и сериализует данные. Далее, я могу комбинировать разные языки программирования, хоть с листом поцару, без разницы, в чём же заключается кодогенерация и связанные с этим вещи. Это бинарный формат, который не упаковывается бинарно, но это снижает трафик. Кроме того, это дает возможность типизации, что позволяет интегрировать авторизацию и типизацию, и это уже будет работать не с точки зрения ограничения.

Вот, например, мы взяли Martin Dreaming Hack для кодирования. У нас возникло мало ошибок, а в JSON мы передаем информацию в виде скобочек и кавычек, которые не несут смысловой нагрузки, а нужны только для разметки. В ProtoBuf мы минимизируем количество передаваемой информации.

Теперь, Владимир, расскажите, чем JSON-RPC отличается от gRPC. Честно говоря, я ни разу не использовал JSON-RPC, но, скорее всего, это просто тот же тип RPC. Грубо говоря, происходит какой-то метод, и, как я понимаю, запрос-ответ осуществляется в виде JSON. Могу ошибаться, так как не использовал этот формат. Если кто-то знает, может подсказать.

Хорошо, давайте поговорим про Under-fetching и Over-fetching. Кто-то сталкивался с этой проблемой при проектировании API? Идея такова: допустим, я пишу API для соцсети ВКонтакте, и у меня пока его использует только 100 приложений. Когда пользователь запрашивает посты, я сразу отдаю посты с комментариями и лайками. Потом наше приложение переходит на мобильную версию, и мобильные разработчики говорят, что им нужны только посты, а лайки и комментарии не важны. Поэтому я всё равно отправлю им ту же самую информацию, и получается over-fetching, когда я передаю лишние данные.

А если у меня была мобильная версия, и теперь я захот сделать десктопное приложение, нужны комментарии и лайки, а для верстки я передавал только посты, то у меня будет under-fetching. Приложение будет получать посты и для каждого поста делать дополнительные запросы для получения лайков и комментариев. Как идеал, стоит избегать этих проблем, но не всегда это возможно.

Существуют устоявшиеся каноны, легаси и прочие вещи, которые плохо сочетаются с этими подходами. Также есть такие вещи, как фильтрация: если я хочу вернуть только имя и возраст, я это осуществлю, выбрав нужные поля для возврата. Мы можем рассматривать наш сервис как базу данных с соответствующими методами.

Теперь по поводу кастомизации. Есть термин «GraphQL», который связан с кастомизацией ответов. Например, когда мы хотим создать пользователей и подписаться на определенные события. 

Давайте подведем итоги: SAP уже мертва, я бы не рекомендовал её. Обычно для API используется REST для клиентского взаимодействия, а gRPC — для внутренних микросервисов. gRPC становится всё более популярным из-за своей понятности и эффективности по сравнению с REST. Когда нужен кастомизированный запрос, можно использовать GraphQL.

Также хочу обсудить термин «RESTful»: я могу писать REST и использовать JSON, а также различные методы и параметры ответа. Однако, если я возвращаю данные в нестандартных форматах, это может не считаться REST. Важно соблюдение стандартов, чтобы сервис был RESTful.




# Observability

## Observability: Основы и компоненты

Observability (наблюдаемость) — это способность понимать состояние системы через сбор и анализ данных, таких как метрики, логи, трейсы и профили. Она позволяет выявлять проблемы, отслеживать производительность и дебажить сбои. В контексте высоконагруженных систем, таких как Яндекс.Такси, observability критически важна для обеспечения надёжности и быстрого реагирования на инциденты.

**Аналогия**: Observability — как медицинские датчики на пациенте. Они показывают пульс (метрики), записывают симптомы (логи), отслеживают путь болезни (трейсы) и делают снимки состояния (профили), чтобы врач мог поставить диагноз.

### 1. Мониторинг и метрики

#### Что такое метрики?

Метрики — это числовые показатели, которые отражают состояние системы. Они собираются путём инкремента переменных в приложении (например, счётчик запросов) и периодически отправляются в систему мониторинга или собираются внешним агентом.

- **Как работает**:
    - Приложение инкрементирует счётчики (например, `requests_total++` при каждом запросе).
    - Метрики собираются с заданной периодичностью (например, раз в 10 секунд).
    - На основе метрик строятся дашборды для визуализации (например, в Grafana).
- **Пример**:
    - Вы замечаете, что использование памяти сервисом превысило 20%. Это сигнал для расследования.
    - Метрика `requests_per_second` показывает всплеск нагрузки в 2 часа ночи, что требует анализа.
- **Аналогия**: Метрики — как спидометр в машине, показывающий текущую скорость и расход топлива.

#### Основные метрики

- **RPS (Requests Per Second)**: Количество запросов в секунду.
- **TPS (Transactions Per Second)**: Количество транзакций в секунду.
    - **Отличие от RPS**: Транзакция может включать несколько запросов (например, SQL-запросы внутри одной операции).
- **Latency/Response Time**: Время ответа на запрос (например, 95-й перцентиль = 3 секунды).
- **Error Rate**: Процент ошибочных операций (например, HTTP 500).
- **Системные метрики**:
    - Использование CPU, RAM, диска.
    - Пропускная способность сети (input/output).
    - Размеры очередей, буферов, количество процессов/потоков.
    - Время работы сервиса (uptime/downtime).
- **Пример**: В API Яндекс.Такси отслеживается `rides_estimations_rps` (запросы на расчёт стоимости) и `ride_cancellations_error_rate` (ошибки при отмене заказов).
- **Аналогия**: Эти метрики — как показатели на фитнес-браслете: шаги (RPS), пульс (latency), калории (CPU).

#### Механизм алертов

- Метрики не отслеживаются вручную 24/7.
- Настраиваются алерты, которые срабатывают при превышении пороговых значений (например, `memory_usage > 80%`).
- Алерты отправляют уведомления (например, в Slack или Telegram), и команда начинает расследование.
- **Пример**: Если `error_rate > 5%` для эндпоинта `/orders`, срабатывает алерт, и разработчики проверяют логи.
- **Аналогия**: Алерты — как сигнализация в доме, которая включается, если что-то идёт не так.

#### Инструменты

- **Prometheus**: Сбор и хранение временных рядов метрик.
- **Grafana**: Визуализация дашбордов на основе метрик.
- **Пример**: В Яндекс.Такси Prometheus собирает метрики RPS для `/events/{ride_id}`, а Grafana отображает график нагрузки.

### 2. Трейсинг

#### Что такое трейсинг?

Трейсинг — это отслеживание пути запроса через распределённую систему, состоящую из множества микросервисов. Он помогает понять, где произошла задержка или ошибка.

- **Как работает**:
    - Каждому запросу присваивается уникальный идентификатор (`trace_id`).
    - Сервисы создают "спаны" — записи о выполнении операций с указанием `trace_id`.
    - Спаны отправляются в централизованную систему, где собираются в трейс — цепочку операций.
    - Трейс показывает, какие микросервисы участвовали в запросе, сколько времени заняла каждая операция и где произошла ошибка.
- **Пример**:
    - Запрос к `/rides/estimations` проходит через API-шлюз, сервис маршрутизации и Redis. Трейс показывает, что задержка возникла на этапе обращения к Redis из-за ошибки.
    - В Яндекс.Такси трейсинг помогает понять, почему заказ такси завис на этапе поиска водителя.
- **Аналогия**: Трейсинг — как GPS-трекер для посылки, показывающий, где она задержалась на пути от склада до получателя.

#### Зачем нужен?

- В распределённых системах запрос может проходить через 20 микросервисов.
- Без трейсинга поиск проблемы требует просмотра логов на каждом сервере, что неэффективно.
- Трейсинг позволяет собрать все данные в одном месте и построить граф зависимостей между сервисами.

#### Инструментирование

- Спаны создаются автоматически библиотеками (например, OpenTelemetry).
- Контекст (`trace_id`) пробрасывается через HTTP-заголовки или другие механизмы.
- **Пример**: В Go библиотека OpenTelemetry добавляет `trace_id` к каждому HTTP-запросу, и спаны отправляются в Jaeger.
- **Аналогия**: Спаны — как маркировка на багаже в аэропорту, которая позволяет отследить его путь через разные терминалы.

#### Инструменты

- **Jaeger**: Визуализация трейсов и анализ задержек.
- **Zipkin**: Альтернатива для трейсинга.
- **Пример**: В Яндекс.Такси Jaeger показывает, что эндпоинт `/orders` тормозит из-за долгого ответа от сервиса геолокации.

### 3. Логирование

#### Что такое логирование?

Логирование — это запись событий приложения в файлы или централизованную систему для последующего анализа. Логи помогают понять, что происходило в системе во время сбоя.

- **Как работает**:
    - Приложение пишет логи (например, "Order created: ride_001").
    - Логи либо хранятся локально, либо отправляются в централизованную систему.
    - Пользователь ищет логи через интерфейс или выполняет запросы (например, поиск по `ride_id`).
- **Пример**:
    - В Яндекс.Такси лог фиксирует ошибку: "Failed to assign driver for ride_001". Это помогает найти причину сбоя.
- **Аналогия**: Логи — как дневник капитана корабля, где записаны все важные события рейса.

#### Проблемы классического логирования

- **Локальные логи**:
    - Приходится подключаться к каждой машине через SSH и искать логи с помощью `grep`.
    - Проблема: в продакшене доступ к серверам может быть ограничен.
    - Пример: В Тинькофф разработчики "прыгали" по серверам, что было неудобно.
- **Частично централизованные логи**:
    - Логи сгружаются на отдельный сервер, но поиск всё равно требует усилий.
    - Пример: В Mail.ru логи хранились на специальных машинах, но поиск был сложным.
- **Аналогия**: Это как искать нужную запись в куче разрозненных тетрадей вместо единого журнала.

#### Современное логирование

- Логи собираются демоном (например, Fluentd или Filebeat) и отправляются в централизованную систему.
- Пользователь взаимодействует с логами через веб-интерфейс, выполняя поиск и агрегацию.
- **Инструменты**:
    - **ELK Stack**: Elasticsearch (хранение), Logstash (обработка), Kibana (визуализация).
    - **Graylog**: Альтернатива для управления логами.
- **Пример**:
    - В Яндекс.Такси Kibana позволяет искать логи по `ride_id` и видеть, почему заказ не был создан.
    - Агрегация показывает, сколько ошибок `driver_assignment_failed` произошло за час.
- **Преимущества**:
    - Удобный поиск без SSH.
    - Возможность фильтрации и агрегации (например, "все ошибки за последние 24 часа").
- **Аналогия**: Централизованное логирование — как библиотека с каталогом, где вы быстро находите нужную книгу по ключевым словам.

### 4. Непрерывное профилирование

#### Что такое профилирование?

Профилирование — это сбор данных о производительности приложения (например, использование CPU, памяти, времени выполнения функций) для анализа узких мест.

- **Как работает**:
    - Сервис периодически снимает профили (например, по CPU и heap) и отправляет их в систему профилирования.
    - При сбое (например, сервис "заумился" в 2:00) разработчик смотрит профиль за 1:55, чтобы понять причину.
- **Пример**:
    - В 2:00 сервис Яндекс.Такси начал потреблять 80% памяти. Профиль показывает, что утечка памяти произошла в функции обработки маршрутов.
    - Сравнение профилей до и после релиза выявляет, что новый код увеличил использование памяти.
- **Аналогия**: Профилирование — как рентген, показывающий, где в организме (системе) возникла проблема.

#### Инструменты

- **Pyroscope**: Сбор и визуализация профилей.
- **Parca**: Непрерывное профилирование для облачных систем.
- **Пример**: В Ozon профилирование выявило, что сервис API "выжирал" память из-за неэффективного кэширования.

#### Зачем нужно?

- Помогает дебажить проблемы производительности (например, утечки памяти).
- Позволяет сравнивать производительность до и после релизов.
- **Пример**: В Яндекс.Такси профилирование показывает, почему эндпоинт `/events/{ride_id}` стал медленнее после обновления.

### 5. Обработка ошибок (Sentry-подобные системы)

#### Что это?

Sentry-подобные системы собирают ошибки и исключения из приложения в централизованное хранилище, упрощая их анализ.

- **Как работает**:
    - При возникновении ошибки (например, паника в Go) она отправляется в систему (например, Sentry) с полным стек-трейсом.
    - Ошибки агрегируются по типу и сервису, позволяя увидеть, где и как часто они происходят.
- **Пример**:
    - В Яндекс.Такси паника в сервисе заказов отправляется в Sentry с сообщением: "Panic: driver not found for ride_001".
    - Разработчик видит, что ошибка произошла на 10 серверах за час, и начинает расследование.
- **Аналогия**: Sentry — как аварийный регистратор в самолёте, фиксирующий все сбои для последующего анализа.

#### Преимущества

- Устраняет необходимость искать ошибки по логам или core dump на каждом сервере.
- Централизованный интерфейс для анализа (например, фильтрация по сервису или типу ошибки).
- **Пример**: В Go коде Sentry SDK отправляет панику с помощью `sentry.CaptureException(err)`.

#### Инструменты

- **Sentry**: Популярная система для обработки ошибок.
- **Kabrio**: Аналог для внутренних систем.
- **Пример**: В Tinkoff Sentry агрегирует ошибки API, упрощая дебаг.

### Почему observability важна при проектировании?

- Без observability запуск сервиса — как вождение машины без приборной панели: непонятно, работает ли он хорошо.
- На этапе проектирования нужно продумать:
    - Какие метрики собирать (RPS, latency, ошибки).
    - Как настроить трейсинг для микросервисов.
    - Куда отправлять логи и как их искать.
    - Как профилировать производительность.
    - Как обрабатывать ошибки.
- **Пример**: Для API Яндекс.Такси важно отслеживать `ride_creation_latency` (время создания заказа), логировать ошибки `driver_assignment_failed` и профилировать сервис маршрутизации.

**Аналогия**: Планирование observability — как установка камер и датчиков в умном доме, чтобы сразу видеть, где что сломалось.

### Инструменты и их применение

|Компонент|Инструменты|Пример использования в Яндекс.Такси|
|---|---|---|
|Мониторинг|Prometheus, Grafana|График RPS для `/rides/estimations`|
|Трейсинг|Jaeger, Zipkin, OpenTelemetry|Анализ задержек в цепочке микросервисов для `/orders`|
|Логирование|ELK Stack, Graylog|Поиск логов по `ride_id` в Kibana|
|Профилирование|Pyroscope, Parca|Диагностика утечек памяти в сервисе маршрутизации|
|Обработка ошибок|Sentry, Kabrio|Агрегация паник при сбоях в создании заказа|

### Заключение

Observability — это не просто набор инструментов, а подход к проектированию систем, который позволяет быстро находить и устранять проблемы. Мониторинг даёт общую картину, трейсинг показывает путь запросов, логирование раскрывает детали, профилирование диагностирует производительность, а системы обработки ошибок упрощают дебаг. При проектировании системы (например, API Яндекс.Такси) важно заранее продумать, как будет реализована наблюдаемость, чтобы сервис был прозрачным и управляемым.

**Аналогия**: Observability — как телескоп для астронома: без него звёзды (система) остаются загадкой, а с ним вы видите каждую деталь.




# ПРАКТИКА. Проектирование API для Яндекс.Такси и Observability

## Практика: Проектирование API для Яндекс.Такси

Цель практики — спроектировать базовый REST API для сервиса, аналогичного Яндекс.Такси. Задача включает определение эндпоинтов для просмотра профилей пассажиров и водителей, истории поездок, расчёта стоимости, заказа и отмены поездок, а также отслеживания статуса поездки. Мы не пишем спецификацию (например, OpenAPI/Swagger) и не проектируем полную систему (базы данных, архитектуру), а фокусируемся на описании методов API, их запросов и ответов. Проектирование начинается с простых методов, постепенно переходя к более сложным, чтобы попрактиковаться в создании API на основе вымышленных требований.

### Подход к проектированию

- **Простота**: Начинаем с простых методов (например, получение профиля), чтобы освоить процесс.
- **Итеративность**: Постепенно добавляем методы, учитывая возможные нюансы (например, RESTful-структура URL, выбор HTTP-методов).
- **Гибкость**: Требования задаём сами, но держим в уме, что в реальной жизни они определяются бизнесом.
- **Аналогия**: Проектирование API — как создание меню для ресторана. Сначала добавляем простые блюда (профили), затем сложные (расчёты, заказы), а потом думаем, как клиенты будут взаимодействовать с официантом (ивенты, статусы).

### Требования (вымышленные)

- Пользователи могут:
    - Просматривать профили пассажиров и водителей.
    - Просматривать историю поездок пассажира.
    - Рассчитывать стоимость и время поездки.
    - Заказывать такси.
    - Отменять заказ.
    - Отслеживать статус поездки (например, прибытие водителя, изменение маршрута).
- Данные включают:
    - Профиль водителя: имя, телефон, автомобиль (с характеристиками).
    - Профиль пассажира: имя, телефон, рейтинг.
    - История поездок: даты, маршруты, стоимость.
    - Расчёт поездки: начальная/конечная точка, стоимость, время.
    - Заказ: идентификатор расчёта, водитель.
    - События поездки: статусы (водитель прибыл, клиент сел, маршрут изменился).

### API Эндпоинты

#### 1. Получение профиля водителя

- **Описание**: Возвращает информацию о водителе по его ID.
- **Метод**: `GET`
- **Эндпоинт**: `/drivers/{driver_id}`
- **Запрос**:
    - Путь: `driver_id` (например, `123`)
- **Ответ** (JSON):
    
    ```json
    {
      "driver_id": "123",
      "name": "John Doe",
      "phone_number": "+1234567890",
      "rating": 4.8,
      "car": {
        "model": "Toyota Camry",
        "color": "Black",
        "license_plate": "ABC123"
      }
    }
    ```
    
- **Нюансы**:
    - Автомобиль представлен как объект, так как имеет несколько характеристик (модель, цвет, номер).
    - Вопрос: Может ли водитель использовать несколько автомобилей? Для простоты предполагаем, что один водитель — один автомобиль. В реальной системе это может быть массив `cars`.
- **Пример**: Клиент запрашивает профиль водителя перед заказом такси, чтобы увидеть рейтинг и автомобиль.
- **Аналогия**: Это как запрос карточки сотрудника в компании — вы получаете имя, контакты и информацию о его рабочем инструменте (автомобиле).

#### 2. Получение профиля пассажира

- **Описание**: Возвращает информацию о пассажире по его ID.
- **Метод**: `GET`
- **Эндпоинт**: `/passengers/{passenger_id}`
- **Запрос**:
    - Путь: `passenger_id` (например, `456`)
- **Ответ** (JSON):
    
    ```json
    {
      "passenger_id": "456",
      "name": "Jane Smith",
      "phone_number": "+0987654321",
      "rating": 4.5
    }
    ```
    
- **Нюансы**:
    - Поля аналогичны профилю водителя, но без автомобиля.
    - Можно добавить дополнительные поля (например, адрес), если потребуется.
- **Пример**: Водитель проверяет профиль пассажира перед началом поездки.
- **Аналогия**: Это как открытие профиля клиента в CRM-системе, чтобы узнать его основные данные.

#### 3. Получение истории поездок пассажира

- **Описание**: Возвращает список поездок пассажира по его ID.
- **Метод**: `GET`
- **Эндпоинт**: `/passengers/{passenger_id}/history`
- **Запрос**:
    - Путь: `passenger_id` (например, `456`)
- **Ответ** (JSON):
    
    ```json
    {
      "passenger_id": "456",
      "history": [
        {
          "ride_id": "789",
          "date": "2025-05-28T10:00:00Z",
          "details": {
            "from": "123 Main St",
            "to": "456 Elm St",
            "cost": 25.50,
            "route": "via Downtown"
          }
        },
        {
          "ride_id": "790",
          "date": "2025-05-27T15:30:00Z",
          "details": {
            "from": "789 Oak St",
            "to": "321 Pine St",
            "cost": 18.75,
            "route": "via Park"
          }
        }
      ]
    }
    ```
    
- **Нюансы**:
    - RESTful-структура: история — это подресурс пассажира (`/passengers/{id}/history`).
    - Поле `history` — массив объектов, каждый из которых содержит идентификатор поездки, дату и детали (откуда, куда, стоимость, маршрут).
    - Можно добавить пагинацию (например, `?page=1&limit=10`) для больших списков.
- **Пример**: Пассажир проверяет свои прошлые поездки в приложении.
- **Аналогия**: Это как просмотр истории заказов в интернет-магазине, где вы видите даты и детали покупок.

#### 4. Расчёт стоимости и времени поездки

- **Описание**: Рассчитывает стоимость и примерное время поездки на основе начальной и конечной точек.
- **Метод**: `GET`
- **Эндпоинт**: `/rides/estimations`
- **Запрос**:
    - Параметры:
        - `from` (например, "123 Main St")
        - `to` (например, "456 Elm St")
    - Пример: `GET /rides/estimations?from=123+Main+St&to=456+Elm+St`
- **Ответ** (JSON):
    
    ```json
    {
      "estimation_id": "est_001",
      "cost": 25.50,
      "duration": 1200
    }
    ```
    
- **Нюансы**:
    - Выбор между `GET` и `POST`:
        - `GET` выбран для простоты, так как параметры (`from`, `to`) помещаются в URL.
        - `POST` мог бы использоваться, если параметров много (например, класс автомобиля, багаж), чтобы передать их в теле запроса.
        - Проблема с `GET`: длинные URL (лимит ~2048 символов) могут выглядеть некрасиво.
    - Возвращается `estimation_id`, чтобы клиент мог использовать его при заказе, избегая повторного расчёта.
    - В реальной системе стоимость может зависеть от времени суток, трафика или класса автомобиля (эконом, комфорт).
- **Пример**: Пользователь вводит адреса в приложении, чтобы узнать, сколько будет стоить поездка.
- **Аналогия**: Это как запрос в калькуляторе доставки, где вы указываете адреса и получаете цену и время.

#### 5. Заказ такси

- **Описание**: Создаёт заказ такси на основе расчёта.
- **Метод**: `POST`
- **Эндпоинт**: `/orders`
- **Запрос** (JSON):
    
    ```json
    {
      "estimation_id": "est_001",
      "from": "123 Main St",
      "to": "456 Elm St"
    }
    ```
    
- **Ответ** (JSON):
    
    ```json
    {
      "ride_id": "ride_001",
      "driver": {
        "driver_id": "123",
        "name": "John Doe",
        "phone_number": "+1234567890"
      },
      "status": "confirmed"
    }
    ```
    
- **Нюансы**:
    - `estimation_id` — необязательный параметр. Если предоставлен, используется ранее рассчитанная стоимость. Если нет, система пересчитывает.
    - В ответе возвращается `ride_id` для дальнейшего отслеживания и информация о водителе.
    - В реальной системе могут быть дополнительные параметры (например, класс автомобиля, комментарии).
- **Пример**: Пользователь подтверждает заказ после выбора адресов, и ему назначается водитель.
- **Аналогия**: Это как оформление заказа в ресторане после выбора блюда из меню.

#### 6. Отмена заказа

- **Описание**: Отменяет существующий заказ по его ID.
- **Метод**: `DELETE`
- **Эндпоинт**: `/orders/{ride_id}`
- **Запрос**:
    - Путь: `ride_id` (например, "ride_001")
- **Ответ**:
    - Статус: HTTP 204 No Content
- **Нюансы**:
    - Выбор `DELETE`:
        - Логично, так как заказ удаляется.
        - Однако в реальной системе "удаление" может быть логическим (устанавливается флаг `cancelled`), чтобы сохранять историю.
    - Альтернативы: `PATCH` или `PUT` для обновления статуса заказа (например, `{ "status": "cancelled"}`).
    - Спорный момент: REST не требует физического удаления, поэтому `DELETE` для простоты, но в реальной системе может быть `PATCH`.
- **Пример**: Пользователь отменяет заказ, если передумал ехать.
- **Аналогия**: Это как отмена брони столика в ресторане — вы уведомляете, и место освобождается.

#### 7. Отслеживание статуса поездки

- **Описание**: Возвращает события, связанные с текущей поездкой (например, прибытие водителя, изменение маршрута).
- **Метод**: `GET`
- **Эндпоинт**: `/events/{ride_id}`
- **Запрос**:
    - Путь: `ride_id` (например, "ride_001")
    - Пример: Клиент опрашивает эндпоинт каждые 5 секунд.
- **Ответ** (JSON):
    
    ```json
    {
      "ride_id": "ride_001",
      "events": [
        {
          "type": "driver_arrived",
          "timestamp": "2025-05-29T10:00:00Z",
          "details": {
            "message": "Driver is waiting at the pickup point"
          }
        },
        {
          "type": "passenger_entered",
          "timestamp": "2025-05-29T10:05:00Z",
          "details": {
            "message": "Passenger has entered the car"
          }
        },
        {
          "type": "position_changed",
          "timestamp": "2025-05-29T10:10:00Z",
          "details": {
            "latitude": 40.7128,
            "longitude": -74.0060
          }
        }
      ]
    }
    ```
    
- **Нюансы**:
    - Используется единый эндпоинт для всех событий, чтобы избежать создания множества методов.
    - Поле `type` определяет тип события (`driver_arrived`, `passenger_entered`, `position_changed`, `route_changed`).
    - Альтернатива: WebSocket для потоковой передачи событий вместо опросов каждые 5 секунд.
    - В реальной системе можно добавить поле `status` (например, "waiting", "in_progress", "completed") для упрощения обработки.
    - События представляют разные структуры, что требует гибкости на стороне клиента.
- **Пример**: Приложение клиента показывает уведомления о прибытии водителя или изменении маршрута.
- **Аналогия**: Это как лента уведомлений в приложении доставки, где вы видите этапы ("Курьер выехал", "Курьер у двери").

### Нюансы проектирования

- **RESTful-структура**:
    - Используются ресурсы (`/drivers`, `/passengers`, `/orders`) и подресурсы (`/passengers/{id}/history`).
    - Параметры пути (`{id}`) для идентификации сущностей, параметры запроса (`?from=...`) для фильтров.
- **Выбор HTTP-методов**:
    - `GET` для чтения (профили, история, события).
    - `POST` для создания (заказ).
    - `DELETE` для удаления (отмена заказа), хотя возможен `PATCH`.
    - Спорные случаи (например, расчёт стоимости) могут быть как `GET`, так и `POST`, в зависимости от объёма параметров.
- **Хранение данных**:
    - `estimation_id` хранится на клиенте для повторного использования при заказе.
    - История отменённых заказов сохраняется на сервере (логическое удаление).
- **Версионирование**:
    - Не реализовано в примере, но в реальной системе API может быть версионирован (например, `/v1/drivers`).
- **Ошибки**:
    - Не рассмотрены, но в реальной системе нужны коды ошибок (например, 404 для несуществующего `driver_id`).
- **Пример реальной системы**: API Яндекс.Такси может быть сложнее, включая геолокацию, маршрутизацию и интеграцию с картами, но базовая структура похожа.

**Аналогия**: Проектирование API — как создание карты города. Вы определяете главные дороги (эндпоинты), перекрёстки (параметры) и указатели (ответы), чтобы пользователи могли легко перемещаться.

### Домашнее задание

- **Задача**: Спроектировать аналогичный REST API для сервиса, похожего на Яндекс.Такси, описав методы, запросы и ответы.
- **Цель**: Закрепить навыки проектирования API, начиная с простых методов и переходя к сложным.
- **Рекомендации**:
    - Начните с простых эндпоинтов (например, профили).
    - Подумайте о RESTful-структуре и выборе HTTP-методов.
    - Учитывайте возможные нюансы (например, хранение `estimation_id`, обработка событий).
- **Аналогия**: Домашка — как черновик архитектурного плана дома. Вы рисуете комнаты (эндпоинты) и двери (методы), чтобы понять, как всё будет работать.

---


